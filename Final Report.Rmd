
---
title: "Practical Machine Learning Project"
output: html_document
---

**Introduction:**

As has been stated in the description of the practical machine learning project this project consists of data collected from various wearable fitness devices as such as FitBit, JawBone, Nike Fuelband etc.. All this data is categorized as Human Activity Recognition and as a part of this they have tried to qualify instead of quantifying the workouts being performed by the users. In the model we are constructing they have collected information about the way people left dumbbells as a part of their exercise routine using various movement coordinate variables. The lifting of the dumbbell is then classified into 5 factors (or Classes)  namely 

*(i)	The correct method (Class A)
*(ii)	throwing the elbows to the front (Class B), 
*(iii)	lifting the dumbbell only halfway (Class C),
*(iv)	lowering the dumbbell only halfway (Class D) 
*(v)	throwing the hips to the front (Class E). 

Read more: http://groupware.les.inf.puc-rio.br/har#ixzz3gxdJ2qD2 

**Preprocessing of the data:**

In order to begin with the data analysis we start by loading the required libraries and then loading the given datasets.


```{r, messsage = FALSE, warning = FALSE}
###Loading libraries
library(caret)
library(randomForest)
library(rpart)
library(rpart.plot)
library(knitr)
###Reading in the datasets
setwd("C:/Users/Anisha/Desktop/Coursera R")
modeldata<-read.csv("pml-training.csv",na.strings = c("NA", ""))
modeldataTest<-read.csv("pml-testing.csv",na.strings = c("NA", ""))

```
Then we clean the datasets by reducing the number of unwanted variables. We get rid of those which consists of mostly missing values and also eliminate certain numeric variables like date timestamp which do not add much value to this particular predictive model.


**Cross Validation of the data:**

We split up the given cleaned dataset into testing and training sets and use a 70:30 split, in order to cross validate our predictive model.

```{r}
###Partitioning the Training dataset into 70% training and 30% testing sets
inTrain <- createDataPartition(y=modeldata$classe, p=0.7, list=FALSE)
Training2 <- modeldata[inTrain, ]
Testing2 <- modeldata[-inTrain, ]
```
```{r}
###Cleaning the dataset to remove unwanted variables and thereby improving computing efficiency
#summary(modeldata)
summary(modeldata$classe)

###Removing variables which has missing values for all the rows
rm_var = sapply(Training2, function(x) {sum(is.na(x))})
table(rm_var)
rm_columns = names(rm_var[rm_var==13458]) ###100 of the columns have 13458 rows with missing values - this was the result of the table function when it was executed step by step
Training2 = Training2[, !names(Training2) %in% rm_columns]
#str(Training2)

###Removing other unwanted numeric variables such as timestamp

Training2<-Training2[c(-1,-3,-4,-5)]
```
**Predictive Models:**

We now use Random Forest and Decision Trees machine leaning algorithms to predict the class of the weight lift depending on the various accelerometer readings

```{r,eval=FALSE} 
###Predicting using ML packages
###Decision Trees
set.seed(333)
modelfitDT <- rpart(classe ~ ., data=Training2, method="class")
rpart.plot(modelfitDT)
predictDT<- predict(modelfitDT,Testing2,type = "class")
confusionMatrix(predictDT, Testing2$classe)
```
```{r,eval=FALSE}
###Random Forests - with cross validation
#modelfitRF<-train(Training2$classe ~ ., method="rf", trControl=trainControl(method = "cv", number = 4), data=Training2)
##Using the randomforest function to save on computation time while compiling the HTML
modelfitRF<-randomForest(classe~.,data = Training2)
print(modelfitRF, digits=3)
predictRF<- predict(modelfitRF,newdata = Testing2)
confusionMatrix(predictRF, Testing2$classe)  
```
Here is the plot of the decision tree. 
```{r, echo=FALSE,eval=FALSE}
rpart.plot(modelfitDT)
```

The results using the Decision tree (Rpart) algorithm


Overall Statistics
                                          
               Accuracy : 0.8253          
                 95% CI : (0.8154, 0.8349)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.7794          
 Mcnemar's Test P-Value : < 2.2e-16       



The results using the Random Forest algorithm


Overall Statistics
                                          
               Accuracy : 0.9978          
                 95% CI : (0.9962, 0.9988)
    No Information Rate : 0.2845          
    P-Value [Acc > NIR] : < 2.2e-16       
                                          
                  Kappa : 0.9972          
 Mcnemar's Test P-Value : NA              



Since the Random Forest yileds a higher accuracy we'll be using the same for predicting on the final test set.

```{r,eval=FALSE} 
predictFinal<- predict(modelfitRF,newdata = modeldataTest)
```

The script for submitting the Final Assignment.
```{r,eval=FALSE} 
pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

pml_write_files(predictFinal)
```


